{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amino-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from torch import nn\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_columns=100\n",
    "from multiprocessing import Pool,cpu_count\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "civil-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "musical-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datalib import VentilatorDataRegression\n",
    "import modellib\n",
    "from utils import fc\n",
    "import datalib\n",
    "from model import LinBnReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statistical-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/disks/extra_data/kaggle/ventilator_prediction/'\n",
    "R_MAP = {5: 0, 50: 1, 20: 2}\n",
    "C_MAP = {20: 0, 50: 1, 10: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "differential-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_DIR,'test.csv'))\n",
    "train.breath_id = train.breath_id.map(dict(zip(train.breath_id.unique().tolist(),range(train.breath_id.nunique()))))\n",
    "test.breath_id = train.breath_id.map(dict(zip(train.breath_id.unique().tolist(),range(train.breath_id.nunique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endangered-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07030214545121005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sorted(train.pressure.unique().tolist())\n",
    "m[0]-m[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wireless-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.pressure.value_counts(1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identical-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "train = fc(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "encouraging-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.R = train.R.map(R_MAP)\n",
    "train.C = train.C.map(C_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scenic-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75450/75450 [08:50<00:00, 142.24it/s]\n"
     ]
    }
   ],
   "source": [
    "group_dict={}\n",
    "for i,x in tqdm(train.groupby('breath_id'),total=train.breath_id.nunique()):\n",
    "    m = x.to_dict(orient='records')\n",
    "    group_dict[i] = {k:[a[k] for a in m] for k in [k for k in m[0].keys() if k not in ['id','breath_id']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spare-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_uin_matrix = get_matrix_dict(train[['breath_id','u_in','u_out', 'time_step']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complex-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load('../configs/lstm-regression.yaml')\n",
    "# config = OmegaConf.load('../configs/lstm-classification-v2.yaml')\n",
    "config.model.kwargs[\"output_dim\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subtle-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getattr(datalib,config.dataset.train['class'])(**config.dataset.train['kwargs'],group_dict=group_dict)\n",
    "dl = DataLoader(\n",
    "    dataset=data,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    batch_size=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-shanghai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "basic-broadway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.09 ms, sys: 321 ms, total: 326 ms\n",
      "Wall time: 604 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pleased-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litmodellib import Model\n",
    "# import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electric-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil_okcredit_in/miniconda3/envs/torch-py3.8/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init_type': 'yakama'}\n",
      "LSTMDpReLu(\n",
      "  (rnn): LSTM(148, 1024, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (dp): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "LSTMDpReLu(\n",
      "  (rnn): LSTM(2048, 512, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (dp): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "LSTMDpReLu(\n",
      "  (rnn): LSTM(1024, 256, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (dp): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "LSTMDpReLu(\n",
      "  (rnn): LSTM(512, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (dp): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# joblib.dump(pressure_reverse_dict,'../sorted_pressure_mapper.pkl')\n",
    "lit_model = Model(\n",
    "    config,\n",
    "    num_train_iter=1,\n",
    "    num_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "registered-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lit_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cognitive-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = lit_model.model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "victorian-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 80]), torch.Size([8, 80]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lit_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "settled-guitar",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# joblib.load('../sorted_pressure_mapper.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "purple-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('../pressure_mapper.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "visible-coalition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beautiful-piano",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "valuable-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lit_model.model(m).view(-1,950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "limited-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640, 950])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "administrative-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from losslib import FocalLoss\n",
    "loss = FocalLoss(gamma=0,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "assumed-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "from losslib import FocalLoss\n",
    "loss = FocalLoss(gamma=10,alpha=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "republican-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = FocalLoss2(gamma=10,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "imposed-mistress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7878, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(a.cpu(),m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "massive-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7878, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2(a.cpu(),m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "recreational-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = m['target'].view(-1)\n",
    "targets = F.one_hot(targets,950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "original-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Softmax(1)(a.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "seventh-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "x = torch.rand(12800,4)*random.randint(1,10)\n",
    "x = Variable(x.cuda())\n",
    "l = torch.rand(12800).ge(0.1).long()\n",
    "l = Variable(l.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "crude-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12800, 4]), torch.Size([12800]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "intimate-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 4])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.rand(128,8,4)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "prompt-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1883, device='cuda:0')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(a,m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "stuck-trout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8511, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(a,m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "radical-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss(a.cpu(),m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "suspended-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litmodellib import smoothing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "binary-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import losslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "collectible-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.cuda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "simple-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.alpha.type_as(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "crazy-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], device='cuda:2')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.alpha.type_as(a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "terminal-press",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.5830, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing_loss(getattr(losslib, config.loss[\"class\"])(**config.loss[\"kwargs\"]),a,m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "automated-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "gamma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bacterial-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = m['target'].view(-1)\n",
    "targets = F.one_hot(targets,950)\n",
    "pt = nn.Softmax(dim=1)(a)\n",
    "logpt = torch.log(pt)\n",
    "alpha = torch.tensor([alpha, 1-alpha])\n",
    "at = alpha.gather(0, targets.data.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "exceptional-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([608000]), torch.Size([640, 950]), torch.Size([640, 950]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.shape,pt.shape,logpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "danish-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8511, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "inappropriate-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8595, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(a,m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "apparent-insider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "consistent-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 80, 1024])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(b.permute(0,2,1),a).permute(0,2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "altered-natural",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 80, 80])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "weird-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "# class LSTMAttnClassification(nn.Module):\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "#         self.config = config\n",
    "#         emb_layers = []\n",
    "#         for k in self.config.embedding_layer:\n",
    "#             emb_layers.append(nn.Embedding(**self.config.embedding_layer[k]))\n",
    "#         self.embedding = nn.Sequential(*emb_layers)\n",
    "\n",
    "#         seq_layers = []\n",
    "#         for k in self.config.rnn_layer:\n",
    "#             seq_layers.append(\n",
    "#                 getattr(nn, self.config.rnn_layer[k][\"class\"])(\n",
    "#                     **self.config.rnn_layer[k][\"kwargs\"]\n",
    "#                 )\n",
    "#             )\n",
    "#         self.rnn = nn.Sequential(*seq_layers)\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             *[\n",
    "#                 LinBnReLu(\n",
    "#                     in_dim=2 * 512,\n",
    "#                     out_dim=512,\n",
    "#                     is_bn=False,\n",
    "#                     dropout=0.1,\n",
    "#                 ),\n",
    "#                 LinBnReLu(\n",
    "#                     in_dim=512, out_dim=self.config.output_dim, is_bn=False, dropout=0\n",
    "#                 ),\n",
    "#             ]\n",
    "#         )\n",
    "#         wt_init = getattr(model, self.config.rnn_init[\"class\"])(\n",
    "#             **self.config.rnn_init[\"kwargs\"]\n",
    "#         )\n",
    "#         print(wt_init.__dict__)\n",
    "#         for layer in self.rnn:\n",
    "#             wt_init(layer)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x_cat, x_num = x[\"cat\"], x[\"num\"]\n",
    "#         attn_matrix = x['u_in_matrix']\n",
    "#         x_cat = torch.cat(\n",
    "#             [self.embedding[i](x_cat[:, :, i]) for i in range(len(self.embedding))],\n",
    "#             dim=-1,\n",
    "#         )\n",
    "#         x_in = torch.cat([x_num, x_cat], dim=-1)\n",
    "        \n",
    "#         for layer in self.rnn:\n",
    "#             x_in, _ = layer(x_in)\n",
    "#             wt_x_in = torch.matmul(x_in.permute(0,2,1),attn_matrix.float()).permute(0,2,1)\n",
    "#             x_in = x_in+wt_x_in        \n",
    "#         output = self.fc(x_in)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-rwanda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "impressive-bleeding",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSTMAttnClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-35bd0cd2fd9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMAttnClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTMAttnClassification' is not defined"
     ]
    }
   ],
   "source": [
    "mod = LSTMAttnClassification(config.model['kwargs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "applicable-mexico",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMAttnClassification(\n",
       "  (embedding): Sequential(\n",
       "    (0): Embedding(2, 32)\n",
       "    (1): Embedding(3, 32)\n",
       "    (2): Embedding(3, 32)\n",
       "  )\n",
       "  (rnn): Sequential(\n",
       "    (0): LSTM(148, 512, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (1): LSTM(1024, 512, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): LinBnReLu(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (act): ReLU()\n",
       "      (lin): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): LinBnReLu(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (act): ReLU()\n",
       "      (lin): Linear(in_features=512, out_features=950, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "taken-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mod(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-comment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "metric-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Conv2d(in_channels=1,out_channels=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "practical-spray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 80])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.permute(0,2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "looking-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 80])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(preds.float(),m['u_in_matrix'].float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-detroit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stainless-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.view(-1,950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "based-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640, 950])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "novel-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = m['target'].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "commercial-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 ms, sys: 75 µs, total: 1.88 ms\n",
      "Wall time: 1.55 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.8581, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nn.CrossEntropyLoss()(preds,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "foreign-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss = criterion(y_pred, y_true)\n",
    "\n",
    "    for lag, w in [(1, 8/15), (2, 4/15), (3, 2/15), (4, 1/15)]:\n",
    "        neg_lag_target = nn.ReLU()(y_true - lag)\n",
    "        neg_lag_target = neg_lag_target.long()\n",
    "        neg_lag_loss = criterion(y_pred, neg_lag_target)\n",
    "        pos_lag_target = 949 - nn.ReLU()((949 - (y_true + lag)))\n",
    "        pos_lag_target = pos_lag_target.long()\n",
    "        pos_lag_loss = criterion(y_pred, pos_lag_target)\n",
    "        loss += (neg_lag_loss + pos_lag_loss) * w\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "legislative-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 114 ms, sys: 7.77 ms, total: 122 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(20.5677, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "loss_fn(preds,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "durable-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.stack([preds]*4)\n",
    "m2 = torch.stack([m['target'].view(-1)]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "lonely-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 640, 950]), torch.Size([4, 640]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "worst-dating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2560, 950])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack([x for x in m1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sunset-acrylic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2560])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack([x for x in m2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "international-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = torch.cat(m1,dim=0)\n",
    "m2 = torch.cat(m2,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cutting-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_val(mapping,tensor):\n",
    "    return torch.tensor([mapping[x.item()] for x in tensor])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "absent-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 767 ms, sys: 0 ns, total: 767 ms\n",
      "Wall time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topk = m1.topk(k=3, dim=1).indices\n",
    "true_preds = (\n",
    "    get_true_val(mapping, topk.view(-1))\n",
    "    .view(-1, 3)\n",
    "    .median(dim=1)\n",
    "    .values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dressed-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20480])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-gospel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-server",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "practical-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "mapping = joblib.load('../pressure_mapper.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "digital-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.kwargs['output_dim'] = 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "martial-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model.kwargs['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "difficult-forest",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 261 µs, total: 116 ms\n",
      "Wall time: 24.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33.7162)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "k=1\n",
    "topk = preds.view(-1,950).topk(k=k,dim=1).indices\n",
    "torch.tensor([torch.median(get_true_val(mapping,x)).item() for x in topk]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "parliamentary-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.75 ms, sys: 3.86 ms, total: 11.6 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = get_true_val(mapping,top3.view(-1)).view(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "proud-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 792 µs, sys: 4.05 ms, total: 4.84 ms\n",
      "Wall time: 4.35 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33.7162)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_true_val(mapping,topk.view(-1)).view(-1,k).median(dim=1).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "particular-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 0 ns, total: 12.6 ms\n",
      "Wall time: 3.93 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33.7162)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_true_val(mapping,preds.view(-1,950).argmax(1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "controversial-quantity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8633, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(preds.view(-1,950),m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-outdoors",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "smaller-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_val(mapping,tensor):\n",
    "    return torch.tensor([mapping[x.item()] for x in tensor])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "absent-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_true_val(pressure_reverse_dict,m['target'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "frozen-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_preds = get_true_val(pressure_reverse_dict,preds.argmax(2).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "frank-kitchen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([851, 143, 906, 168, 906, 906, 869, 757, 906, 906, 906, 906, 843,\n",
       "       516, 843, 906, 843, 662, 143, 906, 906, 869, 869, 906, 906, 168,\n",
       "       843, 280, 906, 143, 168, 843, 843, 906, 843, 906, 843, 280, 843,\n",
       "       906, 280, 168, 869, 906, 906, 143, 906, 843, 711, 168, 280, 869,\n",
       "       843, 280, 168, 906, 869, 823, 168, 843, 906, 823, 906, 168, 516,\n",
       "       869, 280, 906, 851, 143, 843, 906, 143, 869, 869, 906, 143, 143,\n",
       "       906, 280, 143, 168, 143, 906, 168, 906, 906, 906, 906, 906, 843,\n",
       "       906, 168, 869, 168, 869, 843, 175, 869, 843, 906, 869, 906, 906,\n",
       "       906, 843, 869, 906, 843, 906, 861, 906, 906, 168, 869, 168, 843,\n",
       "       869, 843, 906, 843, 143, 168, 843, 843, 843, 168, 659, 869, 143,\n",
       "       906, 869, 143, 859, 280, 143, 906, 906, 869, 168, 843, 906, 843,\n",
       "       906, 143, 168, 869, 143, 843, 143, 143, 843, 143, 843, 906, 869,\n",
       "       823, 843, 843, 143, 364, 143, 168, 906, 168, 906, 143, 843, 906,\n",
       "       168, 843, 851, 869, 906, 168, 851, 843, 662, 168, 906, 175, 168,\n",
       "       869, 168, 843, 869, 843, 906, 843, 474, 175, 869, 906, 143, 906,\n",
       "       662, 143, 143, 843, 843, 516, 838, 869, 143, 168, 906, 843, 168,\n",
       "       906, 168, 143, 869, 168, 906, 168, 906, 906, 869, 823, 869, 859,\n",
       "       906, 851, 168, 906, 906, 168, 168, 843, 168, 143, 280, 843, 869,\n",
       "       906, 869, 851, 843, 143, 168, 364, 168, 906, 143, 851, 168, 906,\n",
       "       823, 280, 906, 906, 869, 869, 168, 869, 869, 869, 869, 168, 843,\n",
       "       906, 843, 906, 859, 143, 906, 869, 843, 869, 906, 869, 143, 168,\n",
       "       175, 280, 869, 906, 843, 168, 906, 168, 364, 143, 168, 869, 843,\n",
       "       516, 143, 851, 869, 143, 143, 280, 906, 508, 168, 143, 906, 906,\n",
       "       280, 711, 906, 823, 869, 906, 906, 175, 859, 906, 168, 859, 843,\n",
       "       869, 869, 906, 168, 143, 869, 869, 143, 906, 851, 869, 851, 168,\n",
       "       843, 906, 823, 906, 843, 851, 869, 906, 906, 280, 869, 843, 168,\n",
       "       280, 906, 906, 168, 851, 175, 906, 869, 869, 843, 906, 843, 280,\n",
       "       906, 168, 168, 906, 869, 843, 143, 869, 906, 168, 906, 906, 869,\n",
       "       843, 843, 906, 869, 843, 843, 168, 143, 508, 843, 906, 168, 851,\n",
       "       843, 906, 906, 662, 168, 143, 851, 869, 823, 168, 168, 906, 168,\n",
       "       906, 168, 843, 851, 906, 906, 843, 280, 906, 869, 143, 869, 659,\n",
       "       843, 168, 906, 168, 843, 143, 906, 906, 168, 906, 869, 906, 869,\n",
       "       869, 906, 869, 168, 659, 843, 906, 168, 843, 851, 843, 906, 906,\n",
       "       859, 843, 168, 906, 843, 869, 906, 168, 168, 843, 843, 906, 906,\n",
       "       869, 906, 168, 168, 280, 843, 659, 906, 869, 869, 823, 168, 906,\n",
       "       843, 843, 869, 842, 168, 143, 280, 906, 869, 869, 662, 859, 168,\n",
       "       906, 869, 843, 843, 143, 906, 364, 143, 143, 280, 168, 906, 143,\n",
       "       906, 906, 843, 906, 175, 168, 869, 906, 906, 906, 843, 168, 869,\n",
       "       869, 823, 711, 280, 851, 508, 851, 143, 869, 168, 168, 843, 843,\n",
       "       168, 843, 168, 869, 906, 168, 280, 906, 881, 869, 168, 143, 906,\n",
       "       906, 143, 859, 143, 843, 906, 906, 843, 143, 906, 906, 851, 843,\n",
       "       869, 906, 869, 168, 843, 843, 143, 869, 364, 168, 869, 168, 364,\n",
       "       168, 869, 906, 168, 843, 869, 843, 859, 168, 175, 869, 168, 869,\n",
       "       143, 143, 168, 906, 143, 906, 143, 869, 869, 364, 143, 168, 168,\n",
       "       168, 250, 168, 843, 843, 175, 168, 906, 869, 168, 168, 143, 851,\n",
       "       859, 869, 869, 843, 906, 168, 851, 843, 906, 906, 869, 168, 843,\n",
       "       906, 280, 906, 869, 662, 843, 168, 175, 168, 906, 823, 168, 906,\n",
       "       843, 843, 906, 906, 143, 168, 143, 843, 906, 869, 906, 906, 168,\n",
       "       280, 851, 869, 843, 143, 168, 906, 168, 869, 364, 843, 906, 280,\n",
       "       843, 168, 906])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[preds.argmax(2).view(-1).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_true_val(pressure_reverse_dict,preds.argmax(2).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "removable-netherlands",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([851, 143, 906, 168, 906, 906, 869, 757, 906, 906, 906, 906, 843, 516,\n",
       "        843, 906, 843, 662, 143, 906, 906, 869, 869, 906, 906, 168, 843, 280,\n",
       "        906, 143, 168, 843, 843, 906, 843, 906, 843, 280, 843, 906, 280, 168,\n",
       "        869, 906, 906, 143, 906, 843, 711, 168, 280, 869, 843, 280, 168, 906,\n",
       "        869, 823, 168, 843, 906, 823, 906, 168, 516, 869, 280, 906, 851, 143,\n",
       "        843, 906, 143, 869, 869, 906, 143, 143, 906, 280, 143, 168, 143, 906,\n",
       "        168, 906, 906, 906, 906, 906, 843, 906, 168, 869, 168, 869, 843, 175,\n",
       "        869, 843, 906, 869, 906, 906, 906, 843, 869, 906, 843, 906, 861, 906,\n",
       "        906, 168, 869, 168, 843, 869, 843, 906, 843, 143, 168, 843, 843, 843,\n",
       "        168, 659, 869, 143, 906, 869, 143, 859, 280, 143, 906, 906, 869, 168,\n",
       "        843, 906, 843, 906, 143, 168, 869, 143, 843, 143, 143, 843, 143, 843,\n",
       "        906, 869, 823, 843, 843, 143, 364, 143, 168, 906, 168, 906, 143, 843,\n",
       "        906, 168, 843, 851, 869, 906, 168, 851, 843, 662, 168, 906, 175, 168,\n",
       "        869, 168, 843, 869, 843, 906, 843, 474, 175, 869, 906, 143, 906, 662,\n",
       "        143, 143, 843, 843, 516, 838, 869, 143, 168, 906, 843, 168, 906, 168,\n",
       "        143, 869, 168, 906, 168, 906, 906, 869, 823, 869, 859, 906, 851, 168,\n",
       "        906, 906, 168, 168, 843, 168, 143, 280, 843, 869, 906, 869, 851, 843,\n",
       "        143, 168, 364, 168, 906, 143, 851, 168, 906, 823, 280, 906, 906, 869,\n",
       "        869, 168, 869, 869, 869, 869, 168, 843, 906, 843, 906, 859, 143, 906,\n",
       "        869, 843, 869, 906, 869, 143, 168, 175, 280, 869, 906, 843, 168, 906,\n",
       "        168, 364, 143, 168, 869, 843, 516, 143, 851, 869, 143, 143, 280, 906,\n",
       "        508, 168, 143, 906, 906, 280, 711, 906, 823, 869, 906, 906, 175, 859,\n",
       "        906, 168, 859, 843, 869, 869, 906, 168, 143, 869, 869, 143, 906, 851,\n",
       "        869, 851, 168, 843, 906, 823, 906, 843, 851, 869, 906, 906, 280, 869,\n",
       "        843, 168, 280, 906, 906, 168, 851, 175, 906, 869, 869, 843, 906, 843,\n",
       "        280, 906, 168, 168, 906, 869, 843, 143, 869, 906, 168, 906, 906, 869,\n",
       "        843, 843, 906, 869, 843, 843, 168, 143, 508, 843, 906, 168, 851, 843,\n",
       "        906, 906, 662, 168, 143, 851, 869, 823, 168, 168, 906, 168, 906, 168,\n",
       "        843, 851, 906, 906, 843, 280, 906, 869, 143, 869, 659, 843, 168, 906,\n",
       "        168, 843, 143, 906, 906, 168, 906, 869, 906, 869, 869, 906, 869, 168,\n",
       "        659, 843, 906, 168, 843, 851, 843, 906, 906, 859, 843, 168, 906, 843,\n",
       "        869, 906, 168, 168, 843, 843, 906, 906, 869, 906, 168, 168, 280, 843,\n",
       "        659, 906, 869, 869, 823, 168, 906, 843, 843, 869, 842, 168, 143, 280,\n",
       "        906, 869, 869, 662, 859, 168, 906, 869, 843, 843, 143, 906, 364, 143,\n",
       "        143, 280, 168, 906, 143, 906, 906, 843, 906, 175, 168, 869, 906, 906,\n",
       "        906, 843, 168, 869, 869, 823, 711, 280, 851, 508, 851, 143, 869, 168,\n",
       "        168, 843, 843, 168, 843, 168, 869, 906, 168, 280, 906, 881, 869, 168,\n",
       "        143, 906, 906, 143, 859, 143, 843, 906, 906, 843, 143, 906, 906, 851,\n",
       "        843, 869, 906, 869, 168, 843, 843, 143, 869, 364, 168, 869, 168, 364,\n",
       "        168, 869, 906, 168, 843, 869, 843, 859, 168, 175, 869, 168, 869, 143,\n",
       "        143, 168, 906, 143, 906, 143, 869, 869, 364, 143, 168, 168, 168, 250,\n",
       "        168, 843, 843, 175, 168, 906, 869, 168, 168, 143, 851, 859, 869, 869,\n",
       "        843, 906, 168, 851, 843, 906, 906, 869, 168, 843, 906, 280, 906, 869,\n",
       "        662, 843, 168, 175, 168, 906, 823, 168, 906, 843, 843, 906, 906, 143,\n",
       "        168, 143, 843, 906, 869, 906, 906, 168, 280, 851, 869, 843, 143, 168,\n",
       "        906, 168, 869, 364, 843, 906, 280, 843, 168, 906])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.view(-1,950).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "unusual-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 80, 950])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
