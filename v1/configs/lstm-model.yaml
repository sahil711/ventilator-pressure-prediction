wandb_project: kaggle-ventilator-pressure-prediction
experiment_name: v5-RNN

seq_len: 40 #None

is_u_out: True #False #True

training_type:
  loss: truncated #complete truncated
  metric: truncated #complete truncated

normalization:
  is_norm: True
  is_log_transform: False

dataset:
  train: &train_dataset
    class: VentilatorData2
    kwargs:
      categorical_columns: ['R','C']
      numerical_columns: ['R_1','C_1','time_step', 'u_in','mean_u_in_last_5', 'min_u_in_last_5', 'max_u_in_last_5',
       'std_u_in_last_5', 'mean_u_in_last_10', 'min_u_in_last_10',
       'max_u_in_last_10', 'std_u_in_last_10', 'mean_u_in_next_5',
       'min_u_in_next_5', 'max_u_in_next_5', 'std_u_in_next_5',
       'mean_u_in_next_10', 'min_u_in_next_10', 'max_u_in_next_10',
       'std_u_in_next_10', 'u_in_cumsum', 'u_in_cummean', 'u_in_cummax', 'R+C',
       'R/C', 'u_in/C', 'u_in/R', 'u_in_cumsum/C', 'u_in_cumsum/R',
       'lag_u_in_1', 'lead_u_in_1', 'lag_u_in_2', 'lead_u_in_2', 'lag_u_in_3',
       'lead_u_in_3', 'lag_u_in_4', 'lead_u_in_4', 'auc', 'lag_auc_1',
       'lead_auc_1', 'lag_auc_2', 'lead_auc_2', 'per_change_u_in_lag_u_in_1',
       'per_change_u_in_lead_u_in_1', 'per_change_u_in_lag_u_in_2',
       'per_change_u_in_lead_u_in_2', 'per_change_u_in_lag_u_in_3',
       'per_change_u_in_lead_u_in_3', 'per_change_u_in_lag_u_in_4',
       'per_change_u_in_lead_u_in_4', 'per_change_auc_lag_auc_1',
       'per_change_auc_lead_auc_1', 'per_change_auc_lag_auc_2',
       'per_change_auc_lead_auc_2']
      target_column: pressure

  val: *train_dataset

  test:
    class: VentilatorData2
    kwargs:
      categorical_columns: ['R','C']
      numerical_columns: ['time_step','u_in']

esr:
  monitor: val_MAE
  min_delta: 0.0001
  patience: 40
  verbose: False
  mode: min

num_epochs: &n_epochs 200

batch_size:
    train: 128
    val: 256
num_workers:
    train: 8
    val: 8

optimizer:
    optim_class: Adam
    optim_kwargs:
        lr: &learning_rate 0.001

# schedular:
#     schedular_class: Linear
#     schedular_interval: step
schedular:
    schedular_class: OneCycleLR
    schedular_interval: step
    scheduler_kwargs:
      max_lr: *learning_rate
      epochs: *n_epochs
      div_factor: 30
      pct_start: 0.2
      final_div_factor: 50

# schedular:
#     schedular_class: ReduceLROnPlateau
#     schedular_interval: epoch
#     scheduler_kwargs:
#       mode: min
#       factor: 0.8
#       patience: 3
#       threshold: 0.0001


loss:
  class: L1Loss #L1Loss MSELoss

mp_training: False

model:
  class: LSTMModel
  kwargs:
    embedding_layer:
      R:
        num_embeddings: 3
        embedding_dim: 256
      C:
        num_embeddings: 3
        embedding_dim: 256

    input_dim: &in_dim 566 #32*3+52

    rnn_layer:
      class: LSTM
      kwargs:
        input_size: *in_dim
        hidden_size: 512
        num_layers: 4
        batch_first: True
        bidirectional: True
        dropout: 0

    rnn_init:
      class: InitRNNWeights
      kwargs:
        init_type: yakama #yakama #None #xavier






