wandb_project: kaggle-ventilator-pressure-prediction
experiment_name: khichdi-v1
seq_len: 40
is_u_out: true
topk: 3
create_features: true
create_matrix: false
training_type:
  loss: truncated
  metric: truncated
  is_smoothing: true
normalization:
  is_norm: true
  is_log_transform: false
dataset:
  train:
    class: VentilatorDataClassification
    kwargs:
      categorical_columns:
      - u_out
      - R
      - C
      numerical_columns:
      - time_step
      - u_in
      - mean_u_in_last_5
      - min_u_in_last_5
      - max_u_in_last_5
      - std_u_in_last_5
      - mean_u_in_last_10
      - min_u_in_last_10
      - max_u_in_last_10
      - std_u_in_last_10
      - mean_u_in_next_5
      - min_u_in_next_5
      - max_u_in_next_5
      - std_u_in_next_5
      - mean_u_in_next_10
      - min_u_in_next_10
      - max_u_in_next_10
      - std_u_in_next_10
      - u_in_cumsum
      - u_in_cummean
      - u_in_cummax
      - R+C
      - R/C
      - u_in/C
      - u_in/R
      - u_in_cumsum/C
      - u_in_cumsum/R
      - lag_u_in_1
      - lead_u_in_1
      - lag_u_in_2
      - lead_u_in_2
      - lag_u_in_3
      - lead_u_in_3
      - lag_u_in_4
      - lead_u_in_4
      - auc
      - lag_auc_1
      - lead_auc_1
      - lag_auc_2
      - lead_auc_2
      - per_change_u_in_lag_u_in_1
      - per_change_u_in_lead_u_in_1
      - per_change_u_in_lag_u_in_2
      - per_change_u_in_lead_u_in_2
      - per_change_u_in_lag_u_in_3
      - per_change_u_in_lead_u_in_3
      - per_change_u_in_lag_u_in_4
      - per_change_u_in_lead_u_in_4
      - per_change_auc_lag_auc_1
      - per_change_auc_lead_auc_1
      - per_change_auc_lag_auc_2
      - per_change_auc_lead_auc_2
      target_column: pressure
  val:
    class: VentilatorDataClassification
    kwargs:
      categorical_columns:
      - u_out
      - R
      - C
      numerical_columns:
      - time_step
      - u_in
      - mean_u_in_last_5
      - min_u_in_last_5
      - max_u_in_last_5
      - std_u_in_last_5
      - mean_u_in_last_10
      - min_u_in_last_10
      - max_u_in_last_10
      - std_u_in_last_10
      - mean_u_in_next_5
      - min_u_in_next_5
      - max_u_in_next_5
      - std_u_in_next_5
      - mean_u_in_next_10
      - min_u_in_next_10
      - max_u_in_next_10
      - std_u_in_next_10
      - u_in_cumsum
      - u_in_cummean
      - u_in_cummax
      - R+C
      - R/C
      - u_in/C
      - u_in/R
      - u_in_cumsum/C
      - u_in_cumsum/R
      - lag_u_in_1
      - lead_u_in_1
      - lag_u_in_2
      - lead_u_in_2
      - lag_u_in_3
      - lead_u_in_3
      - lag_u_in_4
      - lead_u_in_4
      - auc
      - lag_auc_1
      - lead_auc_1
      - lag_auc_2
      - lead_auc_2
      - per_change_u_in_lag_u_in_1
      - per_change_u_in_lead_u_in_1
      - per_change_u_in_lag_u_in_2
      - per_change_u_in_lead_u_in_2
      - per_change_u_in_lag_u_in_3
      - per_change_u_in_lead_u_in_3
      - per_change_u_in_lag_u_in_4
      - per_change_u_in_lead_u_in_4
      - per_change_auc_lag_auc_1
      - per_change_auc_lead_auc_1
      - per_change_auc_lag_auc_2
      - per_change_auc_lead_auc_2
      target_column: pressure
  test:
    class: VentilatorDataClassification
    kwargs:
      categorical_columns:
      - u_out
      - R
      - C
      numerical_columns:
      - time_step
      - u_in
      - mean_u_in_last_5
      - min_u_in_last_5
      - max_u_in_last_5
      - std_u_in_last_5
      - mean_u_in_last_10
      - min_u_in_last_10
      - max_u_in_last_10
      - std_u_in_last_10
      - mean_u_in_next_5
      - min_u_in_next_5
      - max_u_in_next_5
      - std_u_in_next_5
      - mean_u_in_next_10
      - min_u_in_next_10
      - max_u_in_next_10
      - std_u_in_next_10
      - u_in_cumsum
      - u_in_cummean
      - u_in_cummax
      - R+C
      - R/C
      - u_in/C
      - u_in/R
      - u_in_cumsum/C
      - u_in_cumsum/R
      - lag_u_in_1
      - lead_u_in_1
      - lag_u_in_2
      - lead_u_in_2
      - lag_u_in_3
      - lead_u_in_3
      - lag_u_in_4
      - lead_u_in_4
      - auc
      - lag_auc_1
      - lead_auc_1
      - lag_auc_2
      - lead_auc_2
      - per_change_u_in_lag_u_in_1
      - per_change_u_in_lead_u_in_1
      - per_change_u_in_lag_u_in_2
      - per_change_u_in_lead_u_in_2
      - per_change_u_in_lag_u_in_3
      - per_change_u_in_lead_u_in_3
      - per_change_u_in_lag_u_in_4
      - per_change_u_in_lead_u_in_4
      - per_change_auc_lag_auc_1
      - per_change_auc_lead_auc_1
      - per_change_auc_lag_auc_2
      - per_change_auc_lead_auc_2
esr:
  monitor: val_MAE
  min_delta: 0.0001
  patience: 40
  verbose: false
  mode: min
num_epochs: 100
batch_size:
  train: 32
  val: 128
num_workers:
  train: 8
  val: 8
optimizer:
  optim_class: Adam
  optim_kwargs:
    lr: &learning_rate 1e-3
start_lr: *learning_rate
last_lr: 5e-5

# schedular:
#     schedular_class: MultiplicativeLR
#     schedular_interval: epoch
#     scheduler_kwargs:

schedular:
  schedular_class: OneCycleLR
  schedular_interval: step
  scheduler_kwargs:
    max_lr: *learning_rate
    epochs: 100
    div_factor: 30
    pct_start: 0.2
    final_div_factor: 50
loss:
  class: CrossEntropyLoss
  kwargs:
    reduction: mean
mp_training: False
model:
  class: LSTMTransformerModelClassificationV3
  kwargs:
    embedding_layer:
      u_out:
        num_embeddings: 2
        embedding_dim: 4
      R:
        num_embeddings: 3
        embedding_dim: 4
      C:
        num_embeddings: 3
        embedding_dim: 4
    num_dim: &numerical_dim 52
    cnn_layer:
      layer1:
        class: &input_cnn_class Conv1d
        kwargs:
          in_channels: *numerical_dim
          out_channels: &cnn_out_dim 16
          kernel_size: 3
          padding: 1
          bias: True
      layer2:
        class: *input_cnn_class
        kwargs:
          in_channels: *numerical_dim
          out_channels: *cnn_out_dim
          kernel_size: 5
          padding: 2
          bias: True
      layer3:
        class: *input_cnn_class
        kwargs:
          in_channels: *numerical_dim
          out_channels: *cnn_out_dim
          kernel_size: 7
          padding: 3
          bias: True
      layer4:
        class: *input_cnn_class
        kwargs:
          in_channels: *numerical_dim
          out_channels: *cnn_out_dim
          kernel_size: 9
          padding: 4
          bias: True
      layer5:
        class: *input_cnn_class
        kwargs:
          in_channels: *numerical_dim
          out_channels: *cnn_out_dim
          kernel_size: 11
          padding: 5
          bias: True
      layer6:
        class: *input_cnn_class
        kwargs:
          in_channels: *numerical_dim
          out_channels: *cnn_out_dim
          kernel_size: 15
          padding: 7
          bias: True
    input_dim: &in_dim 64
    rnn_layer:
      layer1:
        class: LSTMDpReLu
        kwargs:
          input_size: *in_dim
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
      layer2:
        class: LSTMDpReLu
        kwargs:
          input_size: 1088 #1184
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
      layer3:
        class: LSTMDpReLu
        kwargs:
          input_size: 2112 #2208
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
      layer4:
        class: LSTMDpReLu
        kwargs:
          input_size: 3136 #3232
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
    fc_input_size: 4160 #4256
    transformer_input_size: 512
    transformer_layer:
      layer1:
        class: TransformerEncoderLayer
        kwargs:
          d_model: 512
          nhead: 128
          dim_feedforward: 512
          dropout: 0.5
      layer2:
        class: TransformerEncoderLayer
        kwargs:
          d_model: 512
          nhead: 64
          dim_feedforward: 512
          dropout: 0.5
      layer3:
        class: TransformerEncoderLayer
        kwargs:
          d_model: 512
          nhead: 32
          dim_feedforward: 512
          dropout: 0.5
      layer4:
        class: TransformerEncoderLayer
        kwargs:
          d_model: 512
          nhead: 16
          dim_feedforward: 512
          dropout: 0.5

    rnn_init:
      class: InitRNNWeights
      kwargs:
        init_type: yakama
    output_dim: 950
