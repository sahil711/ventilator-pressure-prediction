wandb_project: kaggle-ventilator-pressure-prediction
experiment_name: LSTMDpRelu-Transformer-concat-skip-classify-smooth-CE-dp-0.4-finetune

seq_len: 40 #None, 20 more than the seq_len in dataset

is_u_out: True #False #True

topk: 3 #1 #3
create_features: True
create_matrix: False

training_type:
  loss: truncated #complete truncated
  metric: truncated #complete truncated
  is_smoothing: True

normalization:
  is_norm: True
  is_log_transform: False

dataset:
  train: &train_dataset
    class: VentilatorDataClassification
    kwargs:
      categorical_columns: ['u_out','R','C']
      numerical_columns: ['time_step', 'u_in','mean_u_in_last_5', 'min_u_in_last_5', 'max_u_in_last_5',
       'std_u_in_last_5', 'mean_u_in_last_10', 'min_u_in_last_10',
       'max_u_in_last_10', 'std_u_in_last_10', 'mean_u_in_next_5',
       'min_u_in_next_5', 'max_u_in_next_5', 'std_u_in_next_5',
       'mean_u_in_next_10', 'min_u_in_next_10', 'max_u_in_next_10',
       'std_u_in_next_10', 'u_in_cumsum', 'u_in_cummean', 'u_in_cummax', 'R+C',
       'R/C', 'u_in/C', 'u_in/R', 'u_in_cumsum/C', 'u_in_cumsum/R',
       'lag_u_in_1', 'lead_u_in_1', 'lag_u_in_2', 'lead_u_in_2', 'lag_u_in_3',
       'lead_u_in_3', 'lag_u_in_4', 'lead_u_in_4', 'auc', 'lag_auc_1',
       'lead_auc_1', 'lag_auc_2', 'lead_auc_2', 'per_change_u_in_lag_u_in_1',
       'per_change_u_in_lead_u_in_1', 'per_change_u_in_lag_u_in_2',
       'per_change_u_in_lead_u_in_2', 'per_change_u_in_lag_u_in_3',
       'per_change_u_in_lead_u_in_3', 'per_change_u_in_lag_u_in_4',
       'per_change_u_in_lead_u_in_4', 'per_change_auc_lag_auc_1',
       'per_change_auc_lead_auc_1', 'per_change_auc_lag_auc_2',
       'per_change_auc_lead_auc_2']
      target_column: pressure
      # flip_aug: -1
      # shift_aug: -1
      # seq_len: 40


  val:
    class: VentilatorDataClassification
    kwargs:
      categorical_columns: ['u_out','R','C']
      numerical_columns: ['time_step', 'u_in','mean_u_in_last_5', 'min_u_in_last_5', 'max_u_in_last_5',
       'std_u_in_last_5', 'mean_u_in_last_10', 'min_u_in_last_10',
       'max_u_in_last_10', 'std_u_in_last_10', 'mean_u_in_next_5',
       'min_u_in_next_5', 'max_u_in_next_5', 'std_u_in_next_5',
       'mean_u_in_next_10', 'min_u_in_next_10', 'max_u_in_next_10',
       'std_u_in_next_10', 'u_in_cumsum', 'u_in_cummean', 'u_in_cummax', 'R+C',
       'R/C', 'u_in/C', 'u_in/R', 'u_in_cumsum/C', 'u_in_cumsum/R',
       'lag_u_in_1', 'lead_u_in_1', 'lag_u_in_2', 'lead_u_in_2', 'lag_u_in_3',
       'lead_u_in_3', 'lag_u_in_4', 'lead_u_in_4', 'auc', 'lag_auc_1',
       'lead_auc_1', 'lag_auc_2', 'lead_auc_2', 'per_change_u_in_lag_u_in_1',
       'per_change_u_in_lead_u_in_1', 'per_change_u_in_lag_u_in_2',
       'per_change_u_in_lead_u_in_2', 'per_change_u_in_lag_u_in_3',
       'per_change_u_in_lead_u_in_3', 'per_change_u_in_lag_u_in_4',
       'per_change_u_in_lead_u_in_4', 'per_change_auc_lag_auc_1',
       'per_change_auc_lead_auc_1', 'per_change_auc_lag_auc_2',
       'per_change_auc_lead_auc_2']
      target_column: pressure
      # flip_aug: -1
      # shift_aug: -1
      # seq_len: 40


  test:
    class: VentilatorDataClassification
    kwargs:
      categorical_columns: ['u_out','R','C']
      numerical_columns: ['time_step', 'u_in','mean_u_in_last_5', 'min_u_in_last_5', 'max_u_in_last_5',
       'std_u_in_last_5', 'mean_u_in_last_10', 'min_u_in_last_10',
       'max_u_in_last_10', 'std_u_in_last_10', 'mean_u_in_next_5',
       'min_u_in_next_5', 'max_u_in_next_5', 'std_u_in_next_5',
       'mean_u_in_next_10', 'min_u_in_next_10', 'max_u_in_next_10',
       'std_u_in_next_10', 'u_in_cumsum', 'u_in_cummean', 'u_in_cummax', 'R+C',
       'R/C', 'u_in/C', 'u_in/R', 'u_in_cumsum/C', 'u_in_cumsum/R',
       'lag_u_in_1', 'lead_u_in_1', 'lag_u_in_2', 'lead_u_in_2', 'lag_u_in_3',
       'lead_u_in_3', 'lag_u_in_4', 'lead_u_in_4', 'auc', 'lag_auc_1',
       'lead_auc_1', 'lag_auc_2', 'lead_auc_2', 'per_change_u_in_lag_u_in_1',
       'per_change_u_in_lead_u_in_1', 'per_change_u_in_lag_u_in_2',
       'per_change_u_in_lead_u_in_2', 'per_change_u_in_lag_u_in_3',
       'per_change_u_in_lead_u_in_3', 'per_change_u_in_lag_u_in_4',
       'per_change_u_in_lead_u_in_4', 'per_change_auc_lag_auc_1',
       'per_change_auc_lead_auc_1', 'per_change_auc_lag_auc_2',
       'per_change_auc_lead_auc_2']
      # flip_aug: -1
      # shift_aug: -1
      # seq_len: 40


esr:
  monitor: val_MAE
  min_delta: 0.0001
  patience: 300
  verbose: False
  mode: min

num_epochs: &n_epochs 100

batch_size:
    train: 128 #128 #32
    val: 512 #256 64
num_workers:
    train: 8
    val: 8

optimizer:
    optim_class: Adam
    optim_kwargs:
        lr: &learning_rate 1e-4

start_lr: *learning_rate
last_lr: 7e-5

schedular:
    schedular_class: MultiplicativeLR
    schedular_interval: epoch
    # scheduler_kwargs:

# schedular:
#     schedular_class: OneCycleLR
#     schedular_interval: step
#     scheduler_kwargs:
#       max_lr: *learning_rate
#       epochs: *n_epochs
#       div_factor: 30
#       pct_start: 0.2
#       final_div_factor: 50
# schedular:
#     schedular_class: CosineAnnealingLR
#     schedular_interval: epoch
#     scheduler_kwargs:
#       T_max: *n_epochs
#       eta_min: 1e-6

# schedular:
#     schedular_class: ReduceLROnPlateau
#     schedular_interval: epoch
#     scheduler_kwargs:
#       mode: min
#       factor: 0.8
#       patience: 3
#       threshold: 0.0001


loss:
  class: CrossEntropyLoss
  kwargs:
    reduction: mean

# loss:
#   class: FocalLoss2
#   kwargs:
#     gamma: 2
#     alpha: 0.25

mp_training: False

model:
  class: LSTMTransformerModelClassificationV2
  kwargs:
    embedding_layer:
      u_out:
        num_embeddings: 2
        embedding_dim: 4
      R:
        num_embeddings: 3
        embedding_dim: 4
      C:
        num_embeddings: 3
        embedding_dim: 4
    input_dim: 64
    rnn_layer:
      layer1:
        class: LSTMDpReLu
        kwargs:
          input_size: 64
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
      layer2:
        class: LSTMDpReLu
        kwargs:
          input_size: 1088
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
      layer3:
        class: LSTMDpReLu
        kwargs:
          input_size: 2112
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
      layer4:
        class: LSTMDpReLu
        kwargs:
          input_size: 3136
          hidden_size: 512
          num_layers: 1
          batch_first: true
          bidirectional: true
          dropout: 0.4
          is_activation: false
    transformer_layer:
      num_layers: 2
      class: TransformerEncoderLayer
      kwargs:
        d_model: 512
        nhead: 4
        dim_feedforward: 512
        dropout: 0.5
    rnn_init:
      class: InitRNNWeights
      kwargs:
        init_type: yakama
    fc_input_size: 4160
    output_dim: 950






